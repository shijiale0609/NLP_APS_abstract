{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APSMarch2021_download.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSvKrahOVCdo"
      },
      "source": [
        "#!/usr/bin/python\r\n",
        "# -*- coding: UTF-8 -*-\r\n",
        "from urllib.request import urlopen\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Q2urWswFf_",
        "outputId": "5b64c83f-e054-4349-cc4d-7dc19d7a4bb5"
      },
      "source": [
        "!wget https://github.com/shijiale0609/NLP_APS_abstract/raw/main/talk_links_final.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-14 18:25:37--  https://github.com/shijiale0609/NLP_APS_abstract/raw/main/talk_links_final.txt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/shijiale0609/NLP_APS_abstract/main/talk_links_final.txt [following]\n",
            "--2021-02-14 18:25:37--  https://raw.githubusercontent.com/shijiale0609/NLP_APS_abstract/main/talk_links_final.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 540232 (528K) [text/plain]\n",
            "Saving to: ‘talk_links_final.txt’\n",
            "\n",
            "talk_links_final.tx 100%[===================>] 527.57K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-02-14 18:25:38 (10.0 MB/s) - ‘talk_links_final.txt’ saved [540232/540232]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzFFFdyQ7sab"
      },
      "source": [
        "talk_urls = []\n",
        "with open(\"talk_links_final.txt\") as f:\n",
        "  for line in f:\n",
        "    cols = line.split()\n",
        "    #print (cols)\n",
        "    talk_urls.append(cols[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdqLz6gPtrcJ",
        "outputId": "863a8b7e-5301-4fc8-c0ed-eb32fb483bed"
      },
      "source": [
        "print (\"Count of urls of Talks:\", len(talk_urls))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-92lDy458DC7"
      },
      "source": [
        "# list of strings \n",
        "url_list = [] \n",
        "title_list = [] \n",
        "author_list = [] \n",
        "abstract_list = [] \n",
        "\n",
        "print (\"Start : %s\" % time.ctime())\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0, len(talk_urls)):\n",
        "\n",
        "  if i%200 == 0: print (i)\n",
        "\n",
        "  time.sleep(0.01*np.random.rand())\n",
        "\n",
        "  url = talk_urls[i]\n",
        "  html = urlopen(url).read().decode('utf-8')\n",
        "  soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "  title = soup.title\n",
        "  authors_raw = soup.find_all('span', {\"class\": \"largernormal\"})\n",
        "  abstract = soup.find('div', {\"class\": \"largernormal\"})\n",
        "\n",
        "  if abstract != None and title !=None and authors_raw != None:\n",
        "\n",
        "    url_list.append(url)\n",
        "    index = title.get_text().index('Event')\n",
        "    title_list.append(title.get_text()[index+8:-1])\n",
        "    authors = []\n",
        "    for author in authors_raw:\n",
        "      authors.append(author.get_text())\n",
        "    author_list.append(authors)\n",
        "    abstract_list.append(abstract.get_text()[1:-1])\n",
        "  else:\n",
        "    print (i, \"has error\\n\")\n",
        "\n",
        "\n",
        "print (\"End : %s\" % time.ctime())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IwQ6t3DAhyy"
      },
      "source": [
        "df = pd.DataFrame([url_list, title_list, author_list, abstract_list]) \r\n",
        "df= df.transpose()\r\n",
        "print (df.head())\r\n",
        "df.columns=['url','Title','Authors', 'Abstract']\r\n",
        "print (df.head())\r\n",
        "\r\n",
        "df.to_csv('APSMarch2021.csv')\r\n",
        "df.to_pickle(\"./APSMarch2021.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPe_7T-mwmDn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}